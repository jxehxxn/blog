---
layout: post
title:  "Splunk 중급편 Part 2: CIM과 데이터 모델 활용"
date:   2025-07-08 13:30:00 +0900
categories: jekyll update
---

## 시작하며: 각기 다른 데이터를 하나의 언어로

지난 파트에서 우리는 Windows 이벤트 로그, Sysmon, Defender 등 다양한 소스로부터 엔드포인트 데이터를 수집했습니다. 이제 Splunk에는 풍부한 데이터가 쌓이고 있지만, 한 가지 문제가 있습니다. 바로 데이터마다 사용하는 필드 이름이 제각각이라는 점입니다.

예를 들어, 출발지 IP 주소를 어떤 로그는 `src_ip`, 다른 로그는 `SourceAddress`, 또 다른 로그는 `Client_IP` 라고 부릅니다. 이 상태에서는 "`1.2.3.4` IP가 관련된 모든 활동을 찾아줘" 라는 간단한 질문에도 복잡한 SPL을 작성해야 합니다: `(src_ip=1.2.3.4 OR SourceAddress=1.2.3.4 OR Client_IP=1.2.3.4)`

이러한 문제를 해결하고, 이기종 데이터의 사일로를 허물어 진정한 통합 분석을 가능하게 하는 핵심 열쇠가 바로 **CIM(Common Information Model, 공통 정보 모델)** 입니다.

## CIM: Splunk의 데이터 표준화 언어

CIM은 Splunk가 미리 정의해 놓은 **데이터 필드 이름의 표준 규격**입니다. 데이터의 종류(네트워크, 인증, 엔드포인트 등)에 따라 관련된 필드들을 그룹화하고, 표준 필드 이름을 부여한 일종의 '스키마(Schema)'입니다.

*   **예시:** CIM의 'Network Traffic' 데이터 모델은 네트워크 통신과 관련된 모든 이벤트를 표현합니다. 이 모델은 출발지 IP는 `src_ip`, 목적지 IP는 `dest_ip`, 목적지 포트는 `dest_port` 라는 표준 필드 이름을 사용하도록 정의합니다.

**왜 CIM이 중요한가?**

1.  **통합 검색:** 모든 데이터가 CIM을 따르게 되면, `src_ip=1.2.3.4` 라는 단 하나의 SPL만으로 Windows 로그, 방화벽 로그, VPN 로그 등 모든 소스에서 해당 IP의 활동을 한 번에 검색할 수 있습니다.
2.  **앱(App) 호환성:** Splunkbase의 수많은 앱들, 특히 Splunk Enterprise Security(ES)와 같은 프리미엄 앱들은 데이터가 CIM을 따른다고 가정하고 만들어졌습니다. 내 데이터를 CIM에 맞추는 것만으로도 이 강력한 앱들의 기능을 즉시 활용할 수 있습니다.
3.  **분석 효율성:** 분석가는 더 이상 개별 로그의 필드 이름을 외울 필요 없이, CIM 표준에만 집중하여 빠르고 일관된 분석을 수행할 수 있습니다.

## [Hands-on] 기술 애드온(TA)을 이용한 CIM 매핑

그렇다면, `SourceAddress` 같은 필드 이름을 어떻게 CIM 표준인 `src_ip`로 바꿔줄 수 있을까요? 이 과정을 **CIM 매핑** 또는 **데이터 정규화(Normalization)**라고 하며, 이 역할을 해주는 것이 바로 **기술 애드온(TA, Technical Add-on)** 입니다.

TA는 특정 데이터 소스(예: Windows, Sysmon)를 CIM에 맞게 변환해주는 설정들의 집합입니다. 필드 추출, 필드 별칭(alias) 설정, 태그(tag) 지정 등의 작업을 자동으로 수행해 줍니다.

**1. 필수 TA 설치**

우리가 수집한 데이터를 위해 Splunkbase에서 다음 TA들을 다운로드하여 Splunk 서버에 설치합니다.

*   **Splunk Add-on for Microsoft Windows:** Windows 이벤트 로그를 CIM에 매핑합니다.
*   **Splunk Add-on for Microsoft Sysmon:** Sysmon 로그를 CIM에 매핑합니다.

**2. CIM 매핑 확인**

TA가 설치되면, 데이터가 수집될 때 자동으로 CIM 매핑이 이루어집니다. Sysmon 로그를 예로 확인해 보겠습니다.

```spl
index=win_sysmon_logs EventCode=3
```

위 검색 결과에서 이벤트 하나를 펼쳐보면, 원래 Sysmon 로그에 있던 `SourceIp`, `DestinationIp` 필드와 함께, TA에 의해 CIM 표준 필드인 `src_ip`, `dest_ip`가 추가로 생성된 것을 볼 수 있습니다. (내부적으로는 필드 별칭 기능을 사용합니다.)

## 데이터 모델: 가속화된 CIM 데이터 집합

CIM 매핑이 완료된 데이터는 **데이터 모델(Data Model)**을 통해 한 단계 더 발전할 수 있습니다. 데이터 모델은 특정 주제(예: 엔드포인트 활동, 인증)와 관련된 CIM 매핑된 데이터들을 미리 요약하고 구조화해 놓은 것입니다.

가장 큰 장점은 **가속화(Acceleration)** 기능입니다. 데이터 모델을 가속화하면, Splunk는 해당 모델에 포함된 데이터에 대해 별도의 요약 인덱스를 생성합니다. 덕분에 수개월, 수년에 달하는 방대한 원본 데이터를 검색하는 대신, 잘 정돈된 요약본을 검색하게 되어 **검색 속도를 수십, 수백 배까지 향상**시킬 수 있습니다.

### [Hands-on] 데이터 모델을 활용한 초고속 분석

`tstats` 라는 전용 명령어를 사용하면, 가속화된 데이터 모델을 매우 빠르게 검색할 수 있습니다.

*   **지난 30일간, 모든 엔드포인트에서 실행된 모든 프로세스 목록을 5초 안에 확인하기**

    ```spl
    | tstats `summariesonly` count from datamodel=Endpoint.Processes by Processes.process_name
    ```

    *   `from datamodel=Endpoint.Processes`: 'Endpoint' 데이터 모델의 'Processes' 데이터셋을 사용하겠다고 지정합니다.
    *   `by Processes.process_name`: 프로세스 이름을 기준으로 통계를 냅니다.

    만약 이 작업을 원본 로그(`index=win_sysmon_logs EventCode=1 ...`)로 수행했다면, 아마 수 분에서 수십 분이 걸렸을 것입니다. 하지만 가속화된 데이터 모델을 사용하면 거의 즉시 결과를 얻을 수 있습니다.

## 다음 이야기

이번 파트에서는 CIM과 데이터 모델이라는 두 가지 강력한 무기를 통해, 제각각이던 데이터를 표준화하고 분석 속도를 극대화하는 방법을 배웠습니다. 이제 우리는 방대한 엔드포인트 데이터를 빠르고 일관되게 분석할 수 있는 튼튼한 기반을 마련했습니다.

다음 파트에서는 이 기반 위에서 실제 **위협 탐지 시나리오**를 구현해 보겠습니다. 여러 데이터를 넘나드는 상관 분석을 통해, 단일 이벤트로는 찾기 힘든 고도화된 공격의 흔적을 탐지하는 구체적인 방법을 실습합니다.

---
