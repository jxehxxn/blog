---
layout: post
title:  "Splunk 시리즈 Part 4: [Hands-on] 데이터의 가치를 높이는 첫걸음, 데이터 파싱과 인덱싱"
date:   2025-07-08 10:30:00 +0900
categories: jekyll update
---

## 시작하며: '쓰레기 데이터'를 '보물 데이터'로

지난 파트에서 우리는 Splunk에 첫 데이터를 성공적으로 수집했습니다. 특히 샘플 데이터를 업로드하면서 **Source Type**과 **Index**를 직접 지정하는 과정을 경험했습니다. 왜 그때 그런 설정을 해야만 했을까요?

"Garbage in, Garbage out"이라는 말이 있습니다. 데이터를 제대로 정제하고 구조화하지 않으면, 분석 결과 역시 쓰레기일 수밖에 없습니다. 이번 파트에서는 지난 파트의 실습을 복기하며, 데이터를 '보물'로 만드는 가장 중요한 두 가지 개념인 **Source Type**과 **Index**의 중요성과 개념에 대해 깊이 있게 알아보겠습니다.

## Source Type: 데이터의 '종류'를 정의하는 명찰

Source Type은 **"이 데이터가 어떤 종류의 데이터인가?"**를 정의하는 가장 중요한 메타데이터 필드입니다. 지난 실습에서 우리는 업로드한 `secure.log` 파일에 `linux_secure`라는 Source Type을 지정했습니다. 이는 Splunk에게 "지금부터 들어오는 데이터는 리눅스 보안 로그의 형식을 따르니, 그에 맞게 해석해줘!" 라고 알려주는 것과 같습니다.

**왜 Source Type이 중요한가요?**

Splunk는 Source Type을 기준으로 데이터의 구조를 해석하고, 필드를 추출하며, 타임스탬프를 인식합니다. 올바른 Source Type을 지정하는 것은 다음과 같은 이점을 가집니다.

1.  **자동 필드 추출:** Splunk에는 `linux_secure`처럼 널리 사용되는 데이터 형식에 대한 Source Type이 미리 정의되어 있습니다. 해당 Source Type을 지정하는 것만으로, Splunk는 아래 그림과 같이 로그에서 자동으로 중요한 필드(예: `src_ip`, `process`, `user`)를 추출하여 좌측의 'Interesting Fields' 목록에 보여줍니다.
    ![Field Extraction](https://www.splunk.com/content/dam/splunk-blogs/images/en_us/2014/03/fields_blog_1.png)
2.  **정확한 타임스탬프 인식:** 로그마다 `Jul  8 10:00:11` 처럼 시간 형식이 제각각입니다. Source Type 설정에 따라 Splunk가 로그에 기록된 시간을 정확히 파싱하여 검색 가능한 이벤트 시간(`_time` 필드)으로 변환해 줍니다.
3.  **일관된 데이터 관리:** 동일한 종류의 데이터는 동일한 Source Type을 갖게 되므로, `sourcetype="linux_secure"` 와 같은 조건으로 원하는 데이터만 쉽게 찾아 분석하고 관리할 수 있습니다.

## Index: 데이터를 효율적으로 저장하는 '책장'

Index는 수집된 데이터를 **물리적으로 저장하는 공간**을 의미합니다. 데이터베이스의 테이블과 유사한 개념으로 생각할 수 있습니다. 지난 실습에서 우리는 샘플 데이터를 위해 `tutorial_logs`라는 새로운 Index를 만들었습니다. 모든 데이터는 이처럼 특정 Index에 속하게 되며, 지정하지 않으면 기본값인 `main` Index에 저장됩니다.

**왜 Index를 나누어야 하나요?**

모든 데이터를 하나의 Index(`main`)에 저장할 수도 있지만, 대규모 환경에서는 데이터의 종류나 용도에 따라 Index를 분리하는 것이 매우 중요합니다.

1.  **검색 성능 향상:** 검색 시 `index="tutorial_logs"` 조건을 추가하면, Splunk는 수많은 다른 데이터는 쳐다보지도 않고 `tutorial_logs` Index에 저장된 데이터만 검색 대상으로 삼습니다. 이는 전체 데이터를 뒤지는 것보다 훨씬 빠르게 결과를 얻을 수 있게 해줍니다.
2.  **유연한 데이터 보관 주기 설정:** 데이터마다 보관해야 하는 기간이 다릅니다. 예를 들어, 보안 로그(`tutorial_logs`)는 법규 준수를 위해 1년 이상 보관해야 하지만, 개발 환경의 디버그 로그는 1주일만 보관해도 충분할 수 있습니다. Index별로 데이터 보관 주기(Retention Policy)를 다르게 설정하여 저장 공간을 효율적으로 관리할 수 있습니다.
3.  **접근 제어:** 사용자 역할(Role)에 따라 특정 Index에 대한 접근 권한을 부여하거나 제한할 수 있습니다. 예를 들어, 보안팀은 `security` Index에만 접근하고, 개발팀은 `app` Index에만 접근하도록 통제하여 데이터 보안을 강화할 수 있습니다.

### [Recap] 우리는 이미 설정했습니다!

지난 Part 3의 샘플 데이터 업로드 과정에서 우리는 이미 Best Practice를 따라 설정을 완료했습니다.

*   **Source Type 지정:** `secure.log` 파일에 `linux_secure` 라는 명찰을 붙여주었습니다.
*   **Index 생성 및 지정:** `tutorial_logs` 라는 전용 책장을 만들고, 그곳에 데이터를 저장하도록 했습니다.

이처럼 데이터를 수집하는 첫 단계에서 Source Type과 Index를 명확히 정의하고 분리하는 습관은, 향후 데이터가 수십, 수백 테라바이트로 늘어났을 때 엄청난 차이를 만들어낼 것입니다.

## 다음 이야기

이번 파트에서는 Source Type과 Index라는 두 가지 핵심 개념을 통해, 데이터를 체계적으로 분류하고 저장하는 것의 중요성을 다시 한번 확인했습니다.

이제 데이터가 잘 정제되었으니, 본격적으로 데이터를 분석해 볼 차례입니다. 다음 파트에서는 **"[Hands-on] Splunk 검색 언어(SPL) 첫걸음 및 기본 분석"**을 주제로, `tutorial_logs` 인덱스에 저장된 샘플 데이터를 가지고 Splunk의 심장과도 같은 SPL의 기본 문법과 활용법을 익혀보겠습니다.

---
